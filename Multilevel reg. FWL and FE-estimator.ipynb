{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Методы анализа неоднородных данных\n",
    "## Домашнее задание 5 (сдаваемое). Модели с фиксированными эффектами \n",
    "## Deadline: 23.59 3 апреля\n",
    "\n",
    "Задание выполняется на базе данных hw5.dta. Краткое описание данных: \n",
    "\n",
    "* county - номер округа штата Северная Каролина\n",
    "* year - год\n",
    "* lncrime - натуральный логарифм числа преступлений на человека\n",
    "* lnpolice - натуральный логарифм числа полицейских на душу населения \n",
    "* lndensity - натуральный логарифм плотности населения \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1\n",
    "\n",
    "Рассмотрим парную регрессионную модель для оценивания взаимосвязи логарифма числа преступлений на человека (зависимая переменная) и логарифма числа полицейских на душу населения (предиктор). Так как данные панельные, оценить классическую \"объединенную\" модель на всей выборке некорректно. Можно воспользоваться уже знакомой Вам моделью с фиксированными эффектами (имеется в виду базовая модель с разными константами для пространственных единиц). Оценивать такую модель на практике мы пока с Вами не учились, но на данном этапе это и не нужно. \n",
    "* Ваша задача - получить FE-оценку (FE = fixed-effects) коэффициента при предикторе \"логарим числа полицейских на душу населения\" на основе взвевешенных оценок коэффициента при данном предикторе, полученных при оценивании регрессионной модели на отдельных подвыборках (в качестве подвыборки в данном случае выступает округ Северной Каролины)\n",
    "* Опишите, что выступает в качестве \"веса\" для оценок коэффициентов \n",
    "* Объясните алгоритм Ваших действий для получения нужной FE-оценки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>year</th>\n",
       "      <th>lncrime</th>\n",
       "      <th>lnpolice</th>\n",
       "      <th>lndensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>-3.221757</td>\n",
       "      <td>-6.327340</td>\n",
       "      <td>0.836017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>-3.261134</td>\n",
       "      <td>-6.338704</td>\n",
       "      <td>0.845977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>-3.496449</td>\n",
       "      <td>-6.300291</td>\n",
       "      <td>0.850920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>-3.360270</td>\n",
       "      <td>-6.273361</td>\n",
       "      <td>0.852891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>-3.308445</td>\n",
       "      <td>-6.253162</td>\n",
       "      <td>0.860734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   county  year   lncrime  lnpolice  lndensity\n",
       "0       1    81 -3.221757 -6.327340   0.836017\n",
       "1       1    82 -3.261134 -6.338704   0.845977\n",
       "2       1    83 -3.496449 -6.300291   0.850920\n",
       "3       1    84 -3.360270 -6.273361   0.852891\n",
       "4       1    85 -3.308445 -6.253162   0.860734"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_stata('hw5.dta')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = pd.Categorical(df.year)\n",
    "df['county'] = pd.Categorical(df.county)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__FE-estimate__ = weighted sum of coefficients estimated on subsample regressions, where __weights__ is a vector of \"group variance\" (variance of the predictor in a group) divided by the sum of all group variances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_coef = []\n",
    "group_variance = []\n",
    "\n",
    "# run regressions for counties separetely\n",
    "for i in df['county'].unique():\n",
    "    \n",
    "    # save estimated `lnpolice` coefficients\n",
    "    samples_coef.append(sm.ols(formula = 'lncrime ~ lnpolice', \n",
    "                               data = df.loc[df['county'] == i]).fit().params[1]) # lnpolice coef\n",
    "    \n",
    "    # save group variance\n",
    "    group_variance.append(np.var(np.array(df.loc[df['county'] == i, 'lnpolice'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21317326768133676"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(samples_coef * (group_variance/sum(group_variance)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check the results on estimated FE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2131732781708462"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FE_ols = sm.ols(formula = 'lncrime ~ lnpolice + C(county)', data = df).fit()\n",
    "FE_ols.params[-1] # lnpolice coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2\n",
    "\n",
    "Проделайте то же самое упражнение, но уже для случая множественной регрессии. Добавьте в Вашу модель переменную \"натуральный логарифм плотности населения\" в качестве контрольной переменной. \n",
    "\n",
    "* Получите FE-оценку коэффициента при предикторе \"натуральный логарифм числа преступлений на человека\"\n",
    "* Объясните, что изменилось в алгоритме действия для получения нужной оценки в случае множественной регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To derive this estimate one can use the __Frisch–Waugh–Lovell (FWL) theorem__. \n",
    "Theorem (from Greene, 2012): \"in the linear least squares regression of vector y on two sets of variables, X1 and\n",
    "X2, the subvector b2 is the set of coefficients obtained when the residuals from a regression of y on X1 alone are regressed on the set of residuals obtained when each column of X2 is regressed on X1.\"\n",
    "\n",
    "\n",
    "Imagine you're more a 'dirty pool' guy and detest fixed effects. Then the FWL-based algorithm of finging a `lnpolice` coefficient will be as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The algorithm FWL + FE-estimator (find `lnpolice` coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept    2.071260e-15\n",
       "res2         1.090721e-01\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_1 = lnpolice\n",
    "# x_2 = lndensity\n",
    "\n",
    "reg1 = sm.ols(formula = 'lncrime ~ lndensity', data=df).fit().resid # Qy\n",
    "reg2 = sm.ols(formula = 'lnpolice ~ lndensity', data=df).fit().resid # QX\n",
    "# assume that the intersept is a part of x_1, we would regress it only once\n",
    "\n",
    "b = pd.DataFrame(np.column_stack((np.array(reg1), np.array(reg2))), columns=['res1','res2']) # data\n",
    "\n",
    "fin = sm.ols('res1 ~ res2', data=b).fit()\n",
    "fin.params # lnpolice coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept   -2.893472\n",
       "lnpolice     0.109072\n",
       "lndensity    0.490108\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.ols(formula = 'lncrime ~ lnpolice + lndensity', data=df).fit().params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we would prefer to account for the spacial heterogeneity. Let's add some fixed effects in a subtle way!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Qy'] = reg1\n",
    "df['QX'] = reg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_coef_DVA = []\n",
    "group_var_police = []\n",
    "\n",
    "# run regressions for counties separetely\n",
    "for i in df['county'].unique():\n",
    "    \n",
    "    # save estimated `lnpolice` coefficients\n",
    "    final = sm.ols(formula = 'Qy ~ QX', \n",
    "                               data = df.loc[df['county'] == i]).fit()\n",
    "    samples_coef_DVA.append(final.params[1]) # lnpolice coef\n",
    "    \n",
    "    # save group variance\n",
    "    group_var_police.append(np.var(np.array(df.loc[df['county'] == i, 'QX'])))\n",
    "    #group_var_police.append(np.var(np.array(final.resid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2074561735377856"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.array(samples_coef_DVA) * (np.array(group_var_police)/sum(np.array(group_var_police))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check the results on estimated FE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21386567548746904"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FE_ols_DVA = sm.ols(formula = 'lncrime ~ lnpolice + lndensity + C(county)', data = df).fit()\n",
    "FE_ols_DVA.params[-2] # lnpolice coef "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3 (самое важное)\n",
    "\n",
    "Сделайте выводы: \n",
    "* Какие пространственные единицы получают больший, а какие - меньший вес при получении FE-оценки? Критически оцените такую процедуру взвешивания. \n",
    "* На практике мы, как правило, получаем FE-оценки, запуская автоматический алгоритм. Тем не менее, каким образом исследователю может быть полезно знание о процедуре получения FE-оценки? Порассуждайте о том, какое смещение мы получаем в результате оценивания FE-модели вместо оценивания классической регрессионной модели на отдельных подвыборках.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем выводы:\n",
    "\n",
    "* Больший вес получают пространственные единицы с большей условной внутригрупповой вариацией по остаткам 'lnpolice'. Большая вариация несет больше информации, поэтому логично, что она должна сильнее влиять на итоговую оценку коэффициента -- вариацию в данных мы и хотим объяснить. \n",
    "* FE-estimator приведет к смещению в случае отсутсвия внутригрупповой вариации по показателю -- коэффициенты при таких группах обнулятся и не будут влиять на итоговый коэффициент при предикторе в FE-модели. То есть перед выбором в пользу и оценкой FE модели стоит посмотреть на внутрегрупповые вариации по показателю == посмотреть на особенность данных, построить графики с распределениями переменных "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
